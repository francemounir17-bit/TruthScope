"""
TruthScope Streamlit Application
Ù…Ø­Ø±Ùƒ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©/Ø§Ù„Ø´Ø§Ø¦Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
"""

import streamlit as st
import pandas as pd
import numpy as np
import sqlite3
import json
import requests
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import plotly.graph_objects as go
import plotly.express as px
from sentence_transformers import SentenceTransformer, util
import torch
import nltk
from nltk.tokenize import sent_tokenize
import re

# ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª nltk Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="TruthScope - Ù…Ø­Ø±Ùƒ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Ù…Ø®ØµØµ
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #1E3A8A;
        padding: 20px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
        margin-bottom: 30px;
    }
    
    .credibility-card {
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    
    .credibility-high {
        background-color: #d4edda;
        border-left: 5px solid #28a745;
    }
    
    .credibility-medium {
        background-color: #fff3cd;
        border-left: 5px solid #ffc107;
    }
    
    .credibility-low {
        background-color: #f8d7da;
        border-left: 5px solid #dc3545;
    }
    
    .credibility-fake {
        background-color: #721c24;
        color: white;
        border-left: 5px solid #dc3545;
    }
    
    .source-badge {
        display: inline-block;
        padding: 3px 10px;
        border-radius: 15px;
        font-size: 12px;
        margin: 2px;
    }
    
    .stProgress > div > div > div > div {
        background-color: #667eea;
    }
    
    .article-card {
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
        transition: all 0.3s ease;
    }
    
    .article-card:hover {
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        transform: translateY(-2px);
    }
    
    .rtl-text {
        text-align: right;
        direction: rtl;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
</style>
""", unsafe_allow_html=True)

# Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
st.markdown("""
<div class="main-header">
    <h1 style="color: white;">ğŸ” TruthScope - Ù…Ø­Ø±Ùƒ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©</h1>
    <p style="color: white; font-size: 18px;">ØªØ­Ù„ÙŠÙ„ Ù…ØµØ¯Ø§Ù‚ÙŠØ© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØ§Ù„Ø´Ø§Ø¦Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ</p>
</div>
""", unsafe_allow_html=True)

# ============================================
# 1. ÙØ¦Ø§Øª Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„Ø© ÙˆÙ†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ†
# ============================================

class DatabaseManager:
    """Ù…Ø¯ÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª SQLite"""
    
    def __init__(self, db_name="truthscope.db"):
        self.db_name = db_name
        self.init_database()
    
    def get_connection(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        conn = sqlite3.connect(self.db_name, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        return conn
    
    def init_database(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø¬Ø¯Ø§ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT UNIQUE NOT NULL,
                email TEXT UNIQUE,
                password_hash TEXT,
                role TEXT DEFAULT 'user',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                reputation_score INTEGER DEFAULT 100
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS news_articles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                url TEXT UNIQUE,
                source_domain TEXT,
                author TEXT,
                published_date TIMESTAMP,
                collected_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                collection_source TEXT,
                credibility_score REAL DEFAULT 0.0,
                confidence_level REAL DEFAULT 0.0,
                credibility_category TEXT,
                ai_analysis TEXT,
                verified BOOLEAN DEFAULT 0
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_feedback (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                article_id INTEGER NOT NULL,
                vote INTEGER,  -- 1 for agree, -1 for disagree, 0 for neutral
                comment TEXT,
                confidence INTEGER DEFAULT 3,  -- 1-5
                feedback_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (article_id) REFERENCES news_articles (id)
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analysis_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                article_id INTEGER,
                analysis_type TEXT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                result TEXT,
                FOREIGN KEY (article_id) REFERENCES news_articles (id)
            )
        ''')
        
        # Ø¥Ù†Ø´Ø§Ø¡ ÙÙ‡Ø±Ø³ Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_articles_url ON news_articles(url)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_articles_score ON news_articles(credibility_score)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_feedback_article ON user_feedback(article_id)')
        
        conn.commit()
        conn.close()
    
    def save_article(self, article_data: Dict) -> int:
        """Ø­ÙØ¸ Ù…Ù‚Ø§Ù„ Ø¬Ø¯ÙŠØ¯"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO news_articles 
                (title, content, url, source_domain, author, published_date, collection_source)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                article_data['title'],
                article_data['content'],
                article_data.get('url', ''),
                article_data.get('source_domain', ''),
                article_data.get('author', 'Ù…Ø¬Ù‡ÙˆÙ„'),
                article_data.get('published_date', datetime.now()),
                article_data.get('collection_source', 'manual')
            ))
            
            article_id = cursor.lastrowid
            conn.commit()
            return article_id
            
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ù‚Ø§Ù„: {str(e)}")
            return None
        finally:
            conn.close()
    
    def update_article_analysis(self, article_id: int, analysis: Dict):
        """ØªØ­Ø¯ÙŠØ« ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                UPDATE news_articles 
                SET credibility_score = ?, 
                    confidence_level = ?,
                    credibility_category = ?,
                    ai_analysis = ?
                WHERE id = ?
            ''', (
                analysis['credibility_score'],
                analysis['confidence_level'],
                analysis['category'],
                json.dumps(analysis, ensure_ascii=False),
                article_id
            ))
            
            conn.commit()
            
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            cursor.execute('''
                INSERT INTO analysis_logs (article_id, analysis_type, result)
                VALUES (?, ?, ?)
            ''', (article_id, 'ai_analysis', 'success'))
            conn.commit()
            
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}")
        finally:
            conn.close()
    
    def save_feedback(self, article_id: int, feedback_data: Dict):
        """Ø­ÙØ¸ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                INSERT INTO user_feedback (article_id, vote, comment, confidence)
                VALUES (?, ?, ?, ?)
            ''', (
                article_id,
                feedback_data.get('vote', 0),
                feedback_data.get('comment', ''),
                feedback_data.get('confidence', 3)
            ))
            
            conn.commit()
            return True
            
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {str(e)}")
            return False
        finally:
            conn.close()
    
    def get_article(self, article_id: int) -> Optional[Dict]:
        """Ø¬Ù„Ø¨ Ù…Ù‚Ø§Ù„ Ø¨ÙˆØ§Ø³Ø·Ø© ID"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        cursor.execute('SELECT * FROM news_articles WHERE id = ?', (article_id,))
        row = cursor.fetchone()
        conn.close()
        
        if row:
            return dict(row)
        return None
    
    def search_articles(self, query: str = None, limit: int = 50) -> List[Dict]:
        """Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        if query:
            cursor.execute('''
                SELECT * FROM news_articles 
                WHERE title LIKE ? OR content LIKE ?
                ORDER BY collected_date DESC
                LIMIT ?
            ''', (f'%{query}%', f'%{query}%', limit))
        else:
            cursor.execute('''
                SELECT * FROM news_articles 
                ORDER BY collected_date DESC
                LIMIT ?
            ''', (limit,))
        
        rows = cursor.fetchall()
        conn.close()
        
        return [dict(row) for row in rows]
    
    def get_statistics(self) -> Dict:
        """Ø¬Ù„Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        stats = {}
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
        cursor.execute('SELECT COUNT(*) FROM news_articles')
        stats['total_articles'] = cursor.fetchone()[0]
        
        # Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©
        cursor.execute('SELECT AVG(credibility_score) FROM news_articles WHERE credibility_score > 0')
        stats['avg_credibility'] = cursor.fetchone()[0] or 0
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª
        cursor.execute('''
            SELECT credibility_category, COUNT(*) 
            FROM news_articles 
            WHERE credibility_category IS NOT NULL
            GROUP BY credibility_category
        ''')
        stats['category_distribution'] = dict(cursor.fetchall())
        
        # Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª
        cursor.execute('SELECT COUNT(*) FROM user_feedback')
        stats['total_feedbacks'] = cursor.fetchone()[0]
        
        conn.close()
        return stats

# ============================================
# 2. ÙˆØ­Ø¯Ø© Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ============================================

class NewsCollector:
    """ÙˆØ­Ø¯Ø© Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…Ø®ØªÙ„ÙØ©"""
    
    def __init__(self):
        self.trusted_sources = {
            'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©': ['alarabiya.net', 'alarabiya.com'],
            'Ø§Ù„Ø¬Ø²ÙŠØ±Ø©': ['aljazeera.net', 'aljazeera.com'],
            'Ø¨ÙŠ Ø¨ÙŠ Ø³ÙŠ': ['bbc.com', 'bbc.co.uk', 'bbc.com/arabic'],
            'Ø±ÙˆÙŠØªØ±Ø²': ['reuters.com', 'reuters.tv'],
            'ÙØ±Ø§Ù†Ø³ 24': ['france24.com', 'france24.com/ar'],
            'Ø³ÙƒØ§ÙŠ Ù†ÙŠÙˆØ²': ['skynewsarabia.com'],
            'Ø³ÙŠ Ø¥Ù† Ø¥Ù†': ['cnnarabic.com', 'arabic.cnn.com']
        }
    
    def extract_from_url(self, url: str) -> Optional[Dict]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø±Ø§Ø¨Ø·"""
        try:
            response = requests.get(url, timeout=10, headers={
                'User-Agent': 'Mozilla/5.0 TruthScope Bot'
            })
            response.raise_for_status()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ØªØ¨Ø³ÙŠØ·)
            # ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ Ù†Ø³ØªØ®Ø¯Ù… BeautifulSoup Ù„ØªØ­Ù„ÙŠÙ„ HTML
            title = url.split('/')[-1].replace('-', ' ')
            content = "Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹..."
            
            return {
                'title': title,
                'content': content,
                'url': url,
                'source_domain': url.split('/')[2],
                'author': 'Ù…Ø¬Ù‡ÙˆÙ„',
                'published_date': datetime.now(),
                'collection_source': 'manual'
            }
            
        except Exception as e:
            st.warning(f"ØªØ¹Ø°Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {str(e)}")
            return None
    
    def check_source_reliability(self, domain: str) -> float:
        """ÙØ­Øµ Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© Ø§Ù„Ù…ØµØ¯Ø±"""
        domain = domain.lower()
        
        for source_name, source_domains in self.trusted_sources.items():
            for source_domain in source_domains:
                if source_domain in domain:
                    return 85.0 + np.random.uniform(0, 15)  # 85-100 Ù„Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚Ø©
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø·Ø§Ù‚
        score = 50.0
        
        # Ø®ØµÙ… Ù„Ù„Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø©
        suspicious = ['blog', 'free', 'click', 'buzz', 'viral', 'wordpress', 'blogspot']
        for keyword in suspicious:
            if keyword in domain:
                score -= 20
        
        return max(10.0, min(score, 100.0))

# ============================================
# 3. ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ
# ============================================

class CredibilityAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    
    def __init__(self):
        self.model = None
        self.load_model()
        
        # Ù‚ÙˆØ§Ø¹Ø¯ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø´Ø§Ø¦Ø¹Ø§Øª
        self.fake_news_patterns = [
            r'ØªØ£ÙƒÙŠØ¯\s+Ù…ØµØ¯Ø±\s+Ù…Ø·Ù„Ø¹',
            r'ØªÙƒØ´Ù\s+ÙˆØ«Ø§Ø¦Ù‚\s+Ø³Ø±ÙŠØ©',
            r'Ø¨Ø¹Ø¯\s+ØµØ¯Ù…Ø©\s+ÙƒØ¨ÙŠØ±Ø©',
            r'Ù…ÙØ§Ø¬Ø£Ø©\s+ØºÙŠØ±\s+Ù…ØªÙˆÙ‚Ø¹Ø©',
            r'ÙŠÙ†Ø´Ø±\s+Ù„Ø£ÙˆÙ„\s+Ù…Ø±Ø©',
            r'ØµÙˆØ±Ø©\s+ØªØ«Ø¨Øª',
            r'ÙÙŠØ¯ÙŠÙˆ\s+Ù…Ø¯ÙˆÙ‘ÙŠ',
            r'ÙŠÙƒØ´Ù\s+Ø§Ù„Ø³ØªØ§Ø±'
        ]
        
        self.trust_indicators = [
            r'Ù†Ù‚Ù„Ø§Ù‹\s+Ø¹Ù†\s+Ù…ØµØ§Ø¯Ø±\s+Ø±Ø³Ù…ÙŠØ©',
            r'Ø¨Ø­Ø³Ø¨\s+Ø¨ÙŠØ§Ù†\s+ØµØ§Ø¯Ø±',
            r'ØµØ±Ø­\s+Ù…Ø³Ø¤ÙˆÙ„',
            r'Ø£ÙØ§Ø¯Øª\s+ÙˆÙƒØ§Ù„Ø©\s+Ø§Ù„Ø£Ù†Ø¨Ø§Ø¡',
            r'Ù†Ø´Ø±Øª\s+Ø§Ù„Ø¬Ø±ÙŠØ¯Ø©\s+Ø§Ù„Ø±Ø³Ù…ÙŠØ©',
            r'ÙƒØ´Ù\s+Ø§Ù„ØªÙ‚Ø±ÙŠØ±\s+Ø§Ù„Ø±Ø³Ù…ÙŠ'
        ]
    
    def load_model(self):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø®ÙÙŠÙ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ù„Ù‰ Streamlit Cloud
            @st.cache_resource
            def load_ai_model():
                return SentenceTransformer('paraphrase-MiniLM-L6-v2')
            
            self.model = load_ai_model()
            st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ù†Ø¬Ø§Ø­")
            
        except Exception as e:
            st.warning(f"âš ï¸ ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„: {str(e)}")
            st.info("Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ")
    
    def analyze_article(self, article: Dict, collector: NewsCollector) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„ ÙˆØªÙ‚ÙŠÙŠÙ… Ù…ØµØ¯Ø§Ù‚ÙŠØªÙ‡"""
        
        scores = {
            'content_score': 0.0,
            'source_score': 0.0,
            'style_score': 0.0,
            'verification_score': 0.0
        }
        
        # 1. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ØµØ¯Ø±
        if 'source_domain' in article:
            scores['source_score'] = collector.check_source_reliability(article['source_domain'])
        
        # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        scores['content_score'] = self.analyze_content(article.get('content', ''))
        
        # 3. ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙƒØªØ§Ø¨Ø©
        scores['style_score'] = self.analyze_writing_style(article.get('content', ''))
        
        # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø§Ø³Ù‚ (Ù†Ù…ÙˆØ°Ø¬ AI)
        if self.model and article.get('content'):
            scores['verification_score'] = self.analyze_with_ai(article['content'])
        else:
            scores['verification_score'] = 50.0
        
        # 5. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        final_score = self.calculate_final_score(scores)
        
        # 6. ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©
        category = self.categorize_credibility(final_score)
        
        # 7. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙØ³ÙŠØ±Ø§Øª
        explanations = self.generate_explanations(scores, category, article)
        
        return {
            'credibility_score': final_score,
            'confidence_level': self.calculate_confidence(scores),
            'category': category,
            'component_scores': scores,
            'explanations': explanations,
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def analyze_content(self, content: str) -> float:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†Øµ"""
        if not content:
            return 50.0
        
        score = 70.0  # Ø¯Ø±Ø¬Ø© Ø£Ø³Ø§Ø³ÙŠØ©
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø§Øª
        for pattern in self.fake_news_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                score -= 15
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©
        for pattern in self.trust_indicators:
            if re.search(pattern, content, re.IGNORECASE):
                score += 10
        
        # ØªØ­Ù„ÙŠÙ„ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ
        word_count = len(content.split())
        if word_count < 50:
            score -= 10  # Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ù…Ø´Ø¨ÙˆÙ‡Ø©
        elif word_count > 500:
            score += 5   # Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹
        
        return max(0.0, min(score, 100.0))
    
    def analyze_writing_style(self, content: str) -> float:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙƒØªØ§Ø¨Ø©"""
        if not content:
            return 50.0
        
        score = 65.0
        
        # ØªØ­Ù„ÙŠÙ„ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¹Ø¬Ø¨ ÙˆØ§Ù„ØªÙƒØ¨ÙŠØ±
        excl_count = content.count('!')
        ques_count = content.count('?')
        word_count = len(content.split())
        
        if word_count > 0:
            excl_ratio = excl_count / word_count
            if excl_ratio > 0.005:  # Ø£ÙƒØ«Ø± Ù…Ù† 0.5%
                score -= excl_ratio * 1000
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙØ§Øª Ø§Ù„Ù…Ø¨Ø§Ù„Øº ÙÙŠÙ‡Ø§
        exaggeration_words = ['Ù…Ø°Ù‡Ù„', 'ØµØ§Ø¯Ù…', 'Ù…ÙØ§Ø¬Ø¦', 'ÙƒØ§Ø±Ø«Ø©', 'Ø®Ø·ÙŠØ± Ù„Ù„ØºØ§ÙŠØ©']
        for word in exaggeration_words:
            if word in content:
                score -= 5
        
        return max(20.0, min(score, 100.0))
    
    def analyze_with_ai(self, content: str) -> float:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        try:
            if len(content) > 1000:
                content = content[:1000]
            
            # ØªØ±Ù…ÙŠØ² Ø§Ù„Ù†Øµ
            embedding = self.model.encode(content, convert_to_tensor=True)
            
            # Ø¬Ù…Ù„ Ù…Ø±Ø¬Ø¹ÙŠØ© Ù„Ù„ØªØ­Ù‚Ù‚ (Ù…Ø«Ø§Ù„)
            reference_texts = [
                "ØªÙ‚Ø±ÙŠØ± Ø±Ø³Ù…ÙŠ ØµØ§Ø¯Ø± Ø¹Ù† Ø§Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ù…Ø®ØªØµØ© ÙŠØ¤ÙƒØ¯ ØµØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª",
                "Ø®Ø¨Ø± ØºÙŠØ± Ù…Ø¤ÙƒØ¯ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ØµØ§Ø¯Ø± Ø£Ø®Ø±Ù‰",
                "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø¶Ù„Ù„Ø© ØªÙ‡Ø¯Ù Ø¥Ù„Ù‰ Ø§Ù„ØªØ¶Ù„ÙŠÙ„ ÙˆØ§Ù„Ø¥Ø´Ø§Ø¹Ø©"
            ]
            
            reference_embeddings = self.model.encode(reference_texts, convert_to_tensor=True)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
            cos_scores = util.pytorch_cos_sim(embedding, reference_embeddings)[0]
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¥Ù„Ù‰ Ø¯Ø±Ø¬Ø©
            # ÙØ±Ø¶ÙŠØ©: Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù‡ÙŠ Ø§Ù„Ø£ÙƒØ«Ø± Ù…ØµØ¯Ø§Ù‚ÙŠØ©
            credibility_score = float(cos_scores[0]) * 100
            
            return max(0.0, min(credibility_score, 100.0))
            
        except Exception as e:
            st.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ AI: {str(e)}")
            return 50.0
    
    def calculate_final_score(self, scores: Dict) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"""
        weights = {
            'source_score': 0.35,
            'content_score': 0.30,
            'style_score': 0.20,
            'verification_score': 0.15
        }
        
        final_score = 0
        for key, weight in weights.items():
            final_score += scores[key] * weight
        
        return round(final_score, 2)
    
    def calculate_confidence(self, scores: Dict) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
        values = list(scores.values())
        variance = np.var(values)
        
        # ÙƒÙ„Ù…Ø§ Ù‚Ù„ Ø§Ù„ØªØ¨Ø§ÙŠÙ†ØŒ Ø²Ø§Ø¯Øª Ø§Ù„Ø«Ù‚Ø©
        confidence = 100 - (variance * 2)
        
        return round(max(30.0, min(confidence, 100.0)), 2)
    
    def categorize_credibility(self, score: float) -> str:
        """ØªØµÙ†ÙŠÙ Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©"""
        if score >= 80:
            return 'high'  # Ù…ÙˆØ«ÙˆÙ‚
        elif score >= 60:
            return 'medium'  # Ù…Ø¹Ù‚ÙˆÙ„
        elif score >= 40:
            return 'low'  # Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡
        else:
            return 'fake'  # Ø´Ø§Ø¦Ø¹Ø©
    
    def generate_explanations(self, scores: Dict, category: str, article: Dict) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙØ³ÙŠØ±Ø§Øª Ù„Ù„Ù†ØªÙŠØ¬Ø©"""
        explanations = []
        
        if scores['source_score'] < 40:
            explanations.append("Ø§Ù„Ù…ØµØ¯Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ«ÙˆÙ‚")
        elif scores['source_score'] > 80:
            explanations.append("Ø§Ù„Ù…ØµØ¯Ø± Ù…Ø¹Ø±ÙˆÙ ÙˆÙ…ÙˆØ«ÙˆÙ‚")
        
        if scores['content_score'] < 40:
            explanations.append("Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø§Øª")
        elif scores['content_score'] > 70:
            explanations.append("Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…ØªÙˆØ§Ø²Ù† ÙˆÙˆØ§Ù‚Ø¹ÙŠ")
        
        if scores['style_score'] < 40:
            explanations.append("Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø¯Ø±Ø§Ù…ÙŠ ÙˆÙ…Ø¨Ø§Ù„Øº ÙÙŠÙ‡")
        
        if scores['verification_score'] < 40:
            explanations.append("Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¢Ù„ÙŠ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¹Ø¯Ù… Ø§Ù„Ø§ØªØ³Ø§Ù‚")
        
        return {
            'summary': 'ØŒ '.join(explanations) if explanations else 'Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù†ØªÙŠØ¬Ø© Ù…ØªÙˆØ³Ø·Ø©',
            'recommendation': self.get_recommendation(category),
            'source_evaluation': f"ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ØµØ¯Ø±: {scores['source_score']}/100",
            'content_evaluation': f"ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {scores['content_score']}/100"
        }
    
    def get_recommendation(self, category: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØµÙ†ÙŠÙ"""
        recommendations = {
            'high': 'âœ… ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØ«ÙˆÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø±ØŒ Ù„ÙƒÙ† ÙŠÙØ¶Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ØµØ§Ø¯Ø± Ø£Ø®Ø±Ù‰',
            'medium': 'âš ï¸ Ø§Ù„Ø®Ø¨Ø± Ù…Ø¹Ù‚ÙˆÙ„ ÙˆÙ„ÙƒÙ† ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ£ÙƒÙŠØ¯ Ù…Ù† Ù…ØµØ§Ø¯Ø± Ø¥Ø¶Ø§ÙÙŠØ©',
            'low': 'ğŸš¨ Ø§Ù„Ø´ÙƒÙˆÙƒ Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± ÙƒØ¨ÙŠØ±Ø©ØŒ ØªØ¬Ù†Ø¨ Ù†Ø´Ø±Ù‡ Ø¯ÙˆÙ† ØªØ­Ù‚Ù‚',
            'fake': 'â›” Ù‡Ø°Ù‡ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¬Ø­ Ø´Ø§Ø¦Ø¹Ø©ØŒ Ù„Ø§ ØªÙ†Ø´Ø± ÙˆÙ„Ø§ ØªØ´Ø§Ø±Ùƒ'
        }
        return recommendations.get(category, 'ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ­Ù‚Ù‚')

# ============================================
# 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… - Streamlit App
# ============================================

def main():
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
    if 'db' not in st.session_state:
        st.session_state.db = DatabaseManager()
    
    if 'collector' not in st.session_state:
        st.session_state.collector = NewsCollector()
    
    if 'analyzer' not in st.session_state:
        with st.spinner('Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...'):
            st.session_state.analyzer = CredibilityAnalyzer()
    
    # Ø´Ø±ÙŠØ· Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„ØªÙ†Ù‚Ù„
    st.sidebar.markdown("## ğŸ§­ Ø§Ù„ØªÙ†Ù‚Ù„")
    page = st.sidebar.radio(
        "Ø§Ø®ØªØ± Ø§Ù„ØµÙØ­Ø©:",
        ["ğŸ  Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", "ğŸ” ØªØ­Ù„ÙŠÙ„ Ø®Ø¨Ø±", "ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª", "ğŸ“œ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"]
    )
    
    # Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    if page == "ğŸ  Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©":
        show_home_page()
    
    # ØµÙØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¨Ø±
    elif page == "ğŸ” ØªØ­Ù„ÙŠÙ„ Ø®Ø¨Ø±":
        show_analysis_page()
    
    # ØµÙØ­Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    elif page == "ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª":
        show_statistics_page()
    
    # ØµÙØ­Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    elif page == "ğŸ“œ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
        show_database_page()
    
    # ØµÙØ­Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    elif page == "âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª":
        show_settings_page()

def show_home_page():
    """Ø¹Ø±Ø¶ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    
    st.markdown("""
    <div class="rtl-text">
        <h2>Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ TruthScope</h2>
        <p>Ø£Ø¯Ø§Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø´Ø§Ø¦Ø¹Ø§Øª ÙˆØªØ­Ù„ÙŠÙ„ Ù…ØµØ¯Ø§Ù‚ÙŠØ© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.</p>
        
        <h3>ğŸ¯ ÙƒÙŠÙ ØªØ¹Ù…Ù„ Ø§Ù„Ø£Ø¯Ø§Ø©ØŸ</h3>
        <ol>
            <li>Ø£Ø¯Ø®Ù„ Ù†Øµ Ø§Ù„Ø®Ø¨Ø± Ø£Ùˆ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡</li>
            <li>ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØµØ¯Ø± ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ù„Ø£Ø³Ù„ÙˆØ¨</li>
            <li>ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©</li>
            <li>ØªØ­ØµÙ„ Ø¹Ù„Ù‰ ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„ Ù…Ø¹ Ø¯Ø±Ø¬Ø© Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©</li>
        </ol>
        
        <h3>ğŸ” Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…</h3>
        <ul>
            <li>Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ Ù†Ø´Ø±Ù‡Ø§</li>
            <li>Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø§Øª Ø¹Ù„Ù‰ ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„</li>
            <li>Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ØµØ­ÙÙŠÙŠÙ† ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª</li>
            <li>Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø§Øª</li>
        </ul>
        
        <h3>ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©</h3>
    </div>
    """, unsafe_allow_html=True)
    
    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©
    stats = st.session_state.db.get_statistics()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("?? Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª", stats['total_articles'])
    
    with col2:
        st.metric("â­ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©", f"{stats['avg_credibility']:.1f}")
    
    with col3:
        st.metric("ğŸ’¬ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª", stats['total_feedbacks'])
    
    with col4:
        categories = stats.get('category_distribution', {})
        verified_count = sum(categories.get(cat, 0) for cat in ['high', 'medium'])
        st.metric("âœ… Ø£Ø®Ø¨Ø§Ø± Ù…ÙˆØ«ÙˆÙ‚Ø©", verified_count)
    
    # Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø­Ø¯ÙŠØ«Ø©
    st.markdown("### ğŸ“° Ø£Ø­Ø¯Ø« Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª")
    
    articles = st.session_state.db.search_articles(limit=5)
    
    if articles:
        for article in articles:
            display_article_card(article, show_analysis=False)
    else:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø³Ø§Ø¨Ù‚Ø©. Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ù„ÙŠÙ„ Ø£ÙˆÙ„ Ø®Ø¨Ø±!")

def show_analysis_page():
    """ØµÙØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¨Ø±"""
    
    st.markdown("""
    <div class="rtl-text">
        <h2>ğŸ” ØªØ­Ù„ÙŠÙ„ Ù…ØµØ¯Ø§Ù‚ÙŠØ© Ø§Ù„Ø®Ø¨Ø±</h2>
        <p>Ø£Ø¯Ø®Ù„ Ù†Øµ Ø§Ù„Ø®Ø¨Ø± Ø£Ùˆ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„ Ù…ØµØ¯Ø§Ù‚ÙŠØªÙ‡.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
    input_method = st.radio(
        "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„:",
        ["ğŸ“ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù…Ø¨Ø§Ø´Ø±", "ğŸ”— Ø¥Ø¯Ø®Ø§Ù„ Ø±Ø§Ø¨Ø·", "ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"],
        horizontal=True
    )
    
    article_data = None
    
    if input_method == "ğŸ“ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù…Ø¨Ø§Ø´Ø±":
        article_data = get_text_input()
    
    elif input_method == "ğŸ”— Ø¥Ø¯Ø®Ø§Ù„ Ø±Ø§Ø¨Ø·":
        article_data = get_url_input()
    
    elif input_method == "ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
        article_data = search_database()
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¨Ø±
    if article_data and st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„", type="primary", use_container_width=True):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¨Ø¶Ø¹ Ø«ÙˆØ§Ù†Ù"):
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©
            analysis = st.session_state.analyzer.analyze_article(
                article_data, 
                st.session_state.collector
            )
            
            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if 'url' in article_data and article_data['url']:
                article_id = st.session_state.db.save_article(article_data)
                if article_id:
                    st.session_state.db.update_article_analysis(article_id, analysis)
                    article_data['id'] = article_id
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            display_analysis_results(article_data, analysis)
            
            # Ù‚Ø³Ù… Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            st.markdown("---")
            st.markdown("### ğŸ’¬ Ø´Ø§Ø±ÙƒÙ†Ø§ Ø±Ø£ÙŠÙƒ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
            
            if 'id' in article_data:
                display_feedback_section(article_data['id'])
            else:
                st.info("ØªØ¹Ø°Ø± Ø­ÙØ¸ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù„Ø£Ù† Ø§Ù„Ù…Ù‚Ø§Ù„ ØºÙŠØ± Ù…Ø­ÙÙˆØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

def show_statistics_page():
    """ØµÙØ­Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
    
    st.markdown("""
    <div class="rtl-text">
        <h2>ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…</h2>
        <p>Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù….</p>
    </div>
    """, unsafe_allow_html=True)
    
    stats = st.session_state.db.get_statistics()
    
    # Ù…Ø®Ø·Ø· ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©
    st.markdown("### ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©")
    
    articles = st.session_state.db.search_articles(limit=100)
    
    if articles:
        df = pd.DataFrame(articles)
        
        if 'credibility_score' in df.columns:
            # Ù…Ø®Ø·Ø· ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª
            fig = px.histogram(
                df, 
                x='credibility_score',
                nbins=20,
                title='ØªÙˆØ²ÙŠØ¹ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©',
                labels={'credibility_score': 'Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©', 'count': 'Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª'},
                color_discrete_sequence=['#667eea']
            )
            fig.update_layout(bargap=0.1)
            st.plotly_chart(fig, use_container_width=True)
            
            # Ù…Ø®Ø·Ø· ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©
            if 'credibility_category' in df.columns:
                category_counts = df['credibility_category'].value_counts()
                
                fig2 = px.pie(
                    values=category_counts.values,
                    names=category_counts.index,
                    title='ØªÙˆØ²ÙŠØ¹ ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©',
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                fig2.update_traces(textposition='inside', textinfo='percent+label')
                st.plotly_chart(fig2, use_container_width=True)
            
            # Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠ
            st.markdown("### ğŸ“‹ Ù…Ù„Ø®Øµ Ø¥Ø­ØµØ§Ø¦ÙŠ")
            
            stats_summary = {
                'Ø§Ù„Ù…ØªÙˆØ³Ø·': df['credibility_score'].mean(),
                'Ø§Ù„ÙˆØ³ÙŠØ·': df['credibility_score'].median(),
                'Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ': df['credibility_score'].std(),
                'Ø§Ù„Ø£Ø¹Ù„Ù‰': df['credibility_score'].max(),
                'Ø§Ù„Ø£Ø¯Ù†Ù‰': df['credibility_score'].min()
            }
            
            stats_df = pd.DataFrame(list(stats_summary.items()), columns=['Ø§Ù„Ù…Ù‚ÙŠØ§Ø³', 'Ø§Ù„Ù‚ÙŠÙ…Ø©'])
            st.dataframe(stats_df, use_container_width=True)
    
    else:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª")

def show_database_page():
    """ØµÙØ­Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    
    st.markdown("""
    <div class="rtl-text">
        <h2>ğŸ“œ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</h2>
        <p>ØªØµÙØ­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªØ­Ù„ÙŠÙ„Ù‡Ø§.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØµÙÙŠØ©
    col1, col2 = st.columns([2, 1])
    
    with col1:
        search_query = st.text_input("ğŸ” Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰")
    
    with col2:
        credibility_filter = st.selectbox(
            "ØªØµÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©",
            ["Ø§Ù„ÙƒÙ„", "Ù…ÙˆØ«ÙˆÙ‚ (80-100)", "Ù…Ø¹Ù‚ÙˆÙ„ (60-80)", "Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡ (40-60)", "Ø´Ø§Ø¦Ø¹Ø© (Ø£Ù‚Ù„ Ù…Ù† 40)"]
        )
    
    # Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
    articles = st.session_state.db.search_articles(query=search_query if search_query else None)
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ±
    if credibility_filter != "Ø§Ù„ÙƒÙ„":
        if credibility_filter == "Ù…ÙˆØ«ÙˆÙ‚ (80-100)":
            articles = [a for a in articles if a.get('credibility_score', 0) >= 80]
        elif credibility_filter == "Ù…Ø¹Ù‚ÙˆÙ„ (60-80)":
            articles = [a for a in articles if 60 <= a.get('credibility_score', 0) < 80]
        elif credibility_filter == "Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡ (40-60)":
            articles = [a for a in articles if 40 <= a.get('credibility_score', 0) < 60]
        elif credibility_filter == "Ø´Ø§Ø¦Ø¹Ø© (Ø£Ù‚Ù„ Ù…Ù† 40)":
            articles = [a for a in articles if a.get('credibility_score', 0) < 40]
    
    st.markdown(f"### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ({len(articles)} Ù…Ù‚Ø§Ù„Ø©)")
    
    if articles:
        # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¶
        view_mode = st.radio(
            "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹Ø±Ø¶:",
            ["ğŸ“‹ Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ÙŠ", "ğŸª§ Ø¹Ø±Ø¶ Ø¨Ø·Ø§Ù‚Ø§Øª"],
            horizontal=True
        )
        
        if view_mode == "ğŸ“‹ Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ÙŠ":
            # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¬Ø¯ÙˆÙ„
            table_data = []
            for article in articles:
                table_data.append({
                    'ID': article.get('id'),
                    'Ø§Ù„Ø¹Ù†ÙˆØ§Ù†': article.get('title', '')[:100] + '...' if len(article.get('title', '')) > 100 else article.get('title', ''),
                    'Ø§Ù„Ù…ØµØ¯Ø±': article.get('source_domain', ''),
                    'Ø§Ù„ØªØ§Ø±ÙŠØ®': article.get('collected_date', ''),
                    'Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©': f"{article.get('credibility_score', 0):.1f}",
                    'Ø§Ù„ØªØµÙ†ÙŠÙ': article.get('credibility_category', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
                })
            
            df = pd.DataFrame(table_data)
            st.dataframe(df, use_container_width=True)
            
            # Ø®ÙŠØ§Ø± Ø§Ù„ØªØµØ¯ÙŠØ±
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ€ CSV",
                data=csv,
                file_name="truthscope_database.csv",
                mime="text/csv"
            )
        
        else:
            # Ø¹Ø±Ø¶ Ø§Ù„Ø¨Ø·Ø§Ù‚Ø§Øª
            for article in articles:
                display_article_card(article, show_analysis=True)
    
    else:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«")

def show_settings_page():
    """ØµÙØ­Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"""
    
    st.markdown("""
    <div class="rtl-text">
        <h2>âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…</h2>
        <p>ØªØ®ØµÙŠØµ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø´Ø§Ø¦Ø¹Ø§Øª.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø©
    st.markdown("### âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©")
    
    col1, col2 = st.columns(2)
    
    with col1:
        auto_save = st.checkbox("Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹", value=True)
        show_details = st.checkbox("Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ©", value=False)
    
    with col2:
        default_language = st.selectbox("Ø§Ù„Ù„ØºØ© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"])
        theme = st.selectbox("Ø§Ù„Ø³Ù…Ø©", ["ÙØ§ØªØ­Ø©", "Ø¯Ø§ÙƒÙ†Ø©"])
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
    st.markdown("### ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„")
    
    st.info("""
    **Ù…Ø¹Ø§ÙŠÙŠØ± ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©:**
    - **Ù…ÙˆØ«ÙˆÙ‚:** 80-100 Ù†Ù‚Ø·Ø©
    - **Ù…Ø¹Ù‚ÙˆÙ„:** 60-80 Ù†Ù‚Ø·Ø©  
    - **Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡:** 40-60 Ù†Ù‚Ø·Ø©
    - **Ø´Ø§Ø¦Ø¹Ø©:** Ø£Ù‚Ù„ Ù…Ù† 40 Ù†Ù‚Ø·Ø©
    """)
    
    # Ù…ØµØ§Ø¯Ù‚ API (Ù„Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ)
    st.markdown("### ğŸ”‘ Ù…ÙØ§ØªÙŠØ­ API (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    
    with st.expander("Ø¥Ø¶Ø§ÙØ© Ù…ÙØ§ØªÙŠØ­ API Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©"):
        newsapi_key = st.text_input("Ù…ÙØªØ§Ø­ NewsAPI", type="password")
        twitter_key = st.text_input("Ù…ÙØªØ§Ø­ Twitter API", type="password")
        
        if st.button("Ø­ÙØ¸ Ù…ÙØ§ØªÙŠØ­ API"):
            st.success("ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ (Ù‡Ø°Ø§ Ù…Ø«Ø§Ù„ØŒ ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø³ÙŠØªÙ… ØªØ®Ø²ÙŠÙ†Ù‡Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¢Ù…Ù†Ø©)")
    
    # Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    st.markdown("### ğŸ—„ï¸ Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", type="secondary"):
            st.session_state.db.init_database()
            st.success("ØªÙ… ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    with col2:
        if st.button("ğŸ§¹ Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©", type="secondary"):
            st.warning("Ù‡Ø°Ø§ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø³ÙŠØ­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. Ù‡Ù„ Ø£Ù†Øª Ù…ØªØ£ÙƒØ¯ØŸ")
            confirm = st.checkbox("Ù†Ø¹Ù…ØŒ Ø£Ù†Ø§ Ù…ØªØ£ÙƒØ¯")
            if confirm:
                # ÙƒÙˆØ¯ Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
                st.info("ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø³ÙŠØªÙ… Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ù‡Ù†Ø§")
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    st.markdown("### â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…")
    
    sys_info = {
        "Ø¥ØµØ¯Ø§Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚": "1.0.0",
        "Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª": st.session_state.db.get_statistics()['total_articles'],
        "Ø­Ø§Ù„Ø© Ù†Ù…ÙˆØ°Ø¬ AI": "Ù…Ø­Ù…Ù‘Ù„" if st.session_state.analyzer.model else "ØºÙŠØ± Ù…Ø­Ù…Ù‘Ù„",
        "ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ø¯ÙŠØ«": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    for key, value in sys_info.items():
        st.text(f"{key}: {value}")

# ============================================
# 5. Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„ÙˆØ§Ø¬Ù‡Ø©
# ============================================

def get_text_input() -> Optional[Dict]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    
    st.markdown("#### ğŸ“ Ø£Ø¯Ø®Ù„ Ù†Øµ Ø§Ù„Ø®Ø¨Ø±")
    
    title = st.text_input("Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø®Ø¨Ø±", placeholder="Ø£Ø¯Ø®Ù„ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø®Ø¨Ø± Ù‡Ù†Ø§...")
    
    content = st.text_area(
        "Ù†Øµ Ø§Ù„Ø®Ø¨Ø±",
        height=200,
        placeholder="Ø§Ù„ØµÙ‚ Ø£Ùˆ Ø§ÙƒØªØ¨ Ù†Øµ Ø§Ù„Ø®Ø¨Ø± Ù‡Ù†Ø§..."
    )
    
    source = st.text_input("Ø§Ù„Ù…ØµØ¯Ø± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", placeholder="Ø§Ø³Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø£Ùˆ Ø§Ù„ØµØ­ÙŠÙØ©")
    
    if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ", type="primary") and content:
        return {
            'title': title if title else "Ø®Ø¨Ø± Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†",
            'content': content,
            'source_domain': source if source else "Ù…Ø¯Ø®Ù„ ÙŠØ¯ÙˆÙŠ",
            'author': "Ù…Ø³ØªØ®Ø¯Ù…",
            'published_date': datetime.now(),
            'collection_source': 'manual_text'
        }
    
    return None

def get_url_input() -> Optional[Dict]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    
    st.markdown("#### ğŸ”— Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ø®Ø¨Ø±")
    
    url = st.text_input(
        "Ø±Ø§Ø¨Ø· Ø§Ù„Ø®Ø¨Ø±",
        placeholder="https://example.com/news/..."
    )
    
    if st.button("Ø¬Ù…Ø¹ ÙˆØªØ­Ù„ÙŠÙ„", type="primary") and url:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·..."):
            article_data = st.session_state.collector.extract_from_url(url)
            
            if article_data:
                return article_data
            else:
                st.error("ØªØ¹Ø°Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© ÙŠØ¯ÙˆÙŠØ§Ù‹.")
                return None
    
    return None

def search_database() -> Optional[Dict]:
    """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    
    st.markdown("#### ğŸ” Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©")
    
    search_query = st.text_input("ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø«")
    
    if search_query:
        articles = st.session_state.db.search_articles(query=search_query)
        
        if articles:
            st.markdown(f"**ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(articles)} Ù…Ù‚Ø§Ù„Ø©**")
            
            # Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ù„Ù„Ù…Ø®ØªØµØ±
            article_options = {f"{a['title'][:50]}... (Ù…ØµØ¯Ø§Ù‚ÙŠØ©: {a.get('credibility_score', 0):.1f})": a for a in articles[:10]}
            
            selected = st.selectbox("Ø§Ø®ØªØ± Ù…Ù‚Ø§Ù„Ø©:", list(article_options.keys()))
            
            if selected and st.button("Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„", type="primary"):
                return article_options[selected]
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ø¨Ø­Ø«")
    
    return None

def display_analysis_results(article: Dict, analysis: Dict):
    """Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
    
    st.markdown("---")
    st.markdown("## ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
    
    # Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    score = analysis['credibility_score']
    category = analysis['category']
    confidence = analysis['confidence_level']
    
    # ØªØ­Ø¯ÙŠØ¯ Ù„ÙˆÙ† Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©
    if category == 'high':
        css_class = 'credibility-high'
        emoji = "âœ…"
        label = "Ù…ÙˆØ«ÙˆÙ‚"
    elif category == 'medium':
        css_class = 'credibility-medium'
        emoji = "âš ï¸"
        label = "Ù…Ø¹Ù‚ÙˆÙ„"
    elif category == 'low':
        css_class = 'credibility-low'
        emoji = "ğŸš¨"
        label = "Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡"
    else:
        css_class = 'credibility-fake'
        emoji = "â›”"
        label = "Ø´Ø§Ø¦Ø¹Ø©"
    
    st.markdown(f"""
    <div class="credibility-card {css_class}">
        <h3>{emoji} Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©: {score}/100</h3>
        <h4>Ø§Ù„ØªØµÙ†ÙŠÙ: {label}</h4>
        <p>Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {confidence}%</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
    st.progress(score / 100)
    
    # Ø§Ù„ØªÙˆØµÙŠØ©
    st.markdown(f"### ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ©")
    st.info(analysis['explanations']['recommendation'])
    
    # Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ©
    with st.expander("ğŸ“ˆ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª")
            scores = analysis['component_scores']
            
            for key, value in scores.items():
                st.metric(
                    label=get_score_label(key),
                    value=f"{value:.1f}/100"
                )
        
        with col2:
            st.markdown("#### ØªÙØ³ÙŠØ±Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„")
            explanations = analysis['explanations']
            
            st.write(f"**Ù…Ù„Ø®Øµ:** {explanations['summary']}")
            st.write(f"**ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ØµØ¯Ø±:** {explanations.get('source_evaluation', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')}")
            st.write(f"**ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø­ØªÙˆÙ‰:** {explanations.get('content_evaluation', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')}")
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„Ù…Ø¦ÙˆÙŠØ©
        st.markdown("#### Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©")
        weights = {
            "Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© Ø§Ù„Ù…ØµØ¯Ø±": 35,
            "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰": 30,
            "Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙƒØªØ§Ø¨Ø©": 20,
            "Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø¢Ù„ÙŠ": 15
        }
        
        fig = go.Figure(data=[go.Pie(
            labels=list(weights.keys()),
            values=list(weights.values()),
            hole=.3,
            textinfo='label+percent'
        )])
        fig.update_layout(showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
    
    # Ø¹Ø±Ø¶ Ù†Øµ Ø§Ù„Ù…Ù‚Ø§Ù„
    with st.expander("ğŸ“„ Ø¹Ø±Ø¶ Ù†Øµ Ø§Ù„Ù…Ù‚Ø§Ù„"):
        st.markdown(f"**Ø§Ù„Ø¹Ù†ÙˆØ§Ù†:** {article.get('title', 'Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†')}")
        st.markdown(f"**Ø§Ù„Ù…ØµØ¯Ø±:** {article.get('source_domain', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}")
        st.markdown("**Ø§Ù„Ù…Ø­ØªÙˆÙ‰:**")
        st.write(article.get('content', ''))

def display_article_card(article: Dict, show_analysis: bool = True):
    """Ø¹Ø±Ø¶ Ø¨Ø·Ø§Ù‚Ø© Ù…Ù‚Ø§Ù„"""
    
    title = article.get('title', 'Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†')
    source = article.get('source_domain', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')
    date = article.get('collected_date', '')
    score = article.get('credibility_score', 0)
    category = article.get('credibility_category', 'unknown')
    
    # ØªØ­Ø¯ÙŠØ¯ Ù„ÙˆÙ† Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©
    if category == 'high':
        border_color = "#28a745"
        badge_color = "success"
    elif category == 'medium':
        border_color = "#ffc107"
        badge_color = "warning"
    elif category == 'low':
        border_color = "#dc3545"
        badge_color = "danger"
    else:
        border_color = "#721c24"
        badge_color = "dark"
    
    st.markdown(f"""
    <div class="article-card" style="border-left: 5px solid {border_color};">
        <h4>{title[:100]}{'...' if len(title) > 100 else ''}</h4>
        <p style="color: #666; font-size: 14px;">
            <strong>Ø§Ù„Ù…ØµØ¯Ø±:</strong> {source} | 
            <strong>Ø§Ù„ØªØ§Ø±ÙŠØ®:</strong> {str(date)[:10]}
        </p>
    """, unsafe_allow_html=True)
    
    if show_analysis and score > 0:
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            st.progress(score / 100)
        
        with col2:
            st.metric("Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©", f"{score:.1f}")
        
        with col3:
            st.button(
                "Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„", 
                key=f"view_{article.get('id')}",
                on_click=lambda a=article: display_article_details(a)
            )
    
    st.markdown("</div>", unsafe_allow_html=True)

def display_article_details(article: Dict):
    """Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ù…Ù‚Ø§Ù„ (ÙÙŠ ØµÙØ­Ø© Ù…Ù†ÙØµÙ„Ø© Ø£Ùˆ Ù…ÙˆØ¯Ø§Ù„)"""
    
    # ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Streamlit Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ù‚Ø¯ Ù†Ø³ØªØ®Ø¯Ù… ØµÙØ­Ø© Ù…Ù†ÙØµÙ„Ø© Ø£Ùˆ Ù…ÙˆØ¯Ø§Ù„
    st.session_state['selected_article'] = article
    st.rerun()

def display_feedback_section(article_id: int):
    """Ø¹Ø±Ø¶ Ù‚Ø³Ù… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        vote = st.radio(
            "Ù‡Ù„ ØªØªÙÙ‚ Ù…Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŸ",
            ["ğŸ‘ Ø£ÙˆØ§ÙÙ‚", "ğŸ‘ Ù„Ø§ Ø£ÙˆØ§ÙÙ‚", "ğŸ¤· Ù…Ø­Ø§ÙŠØ¯"],
            horizontal=True
        )
    
    with col2:
        confidence = st.slider(
            "Ù…Ø¯Ù‰ Ø«Ù‚ØªÙƒ ÙÙŠ Ø±Ø£ÙŠÙƒ",
            min_value=1,
            max_value=5,
            value=3
        )
    
    with col3:
        comment = st.text_input("ØªØ¹Ù„ÙŠÙ‚Ùƒ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    
    if st.button("Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…", type="secondary"):
        vote_map = {"ğŸ‘ Ø£ÙˆØ§ÙÙ‚": 1, "ğŸ‘ Ù„Ø§ Ø£ÙˆØ§ÙÙ‚": -1, "ğŸ¤· Ù…Ø­Ø§ÙŠØ¯": 0}
        
        feedback_data = {
            'vote': vote_map[vote],
            'comment': comment,
            'confidence': confidence
        }
        
        success = st.session_state.db.save_feedback(article_id, feedback_data)
        
        if success:
            st.success("Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙ‚ÙŠÙŠÙ…Ùƒ! ØªÙ… Ø­ÙØ¸ Ø±Ø£ÙŠÙƒ.")
            
            # ØªØ­Ø¯ÙŠØ« Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª
            update_credibility_based_on_feedback(article_id)
        else:
            st.error("Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªÙ‚ÙŠÙŠÙ….")

def update_credibility_based_on_feedback(article_id: int):
    """ØªØ­Ø¯ÙŠØ« Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
    # Ù‡Ø°Ø§ Ø¯Ø§Ù„Ø© ØªØ¬Ù…ÙŠÙ„ÙŠØ© - ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø³ÙŠØªÙ… Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª
    pass

def get_score_label(key: str) -> str:
    """ØªØ­ÙˆÙŠÙ„ Ù…ÙØªØ§Ø­ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ ØªØ³Ù…ÙŠØ© Ø¹Ø±Ø¨ÙŠØ©"""
    labels = {
        'source_score': 'Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© Ø§Ù„Ù…ØµØ¯Ø±',
        'content_score': 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰',
        'style_score': 'Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙƒØªØ§Ø¨Ø©',
        'verification_score': 'Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø¢Ù„ÙŠ'
    }
    return labels.get(key, key)

# ============================================
# 6. ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# ============================================

if __name__ == "__main__":
    # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    main()
    
    # ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; font-size: 14px;">
        <p>ØªÙ… ØªØ·ÙˆÙŠØ±Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… â¤ï¸ Ùˆ Streamlit</p>
        <p>TruthScope v1.0 | Ù…Ø­Ø±Ùƒ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©</p>
        <p>âš ï¸ Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„Ø¨Ø­Ø«ÙŠØ©</p>
    </div>
    """, unsafe_allow_html=True)